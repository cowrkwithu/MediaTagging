# 구현 설계서

**프로젝트명:** MediaTagging
**버전:** v20260127
**작성일:** 2026-01-27

---

## 1. 개요

본 문서는 동영상 및 사진 AI 태깅 및 검색 웹 애플리케이션의 단계별 구현 계획을 정의한다.
각 단계는 구현 완료 후 테스트를 수행하고, 테스트 결과를 기록한 후 다음 단계로 진행한다.

---

## 2. 현재 구현 상태

### 2.1 완료된 항목

| 구분 | 항목 | 상태 |
|------|------|------|
| 인프라 | PostgreSQL Docker 컨테이너 | ✅ 완료 |
| 인프라 | DB 마이그레이션 (Alembic) | ✅ 완료 |
| 백엔드 | FastAPI 기본 구조 | ✅ 완료 |
| 백엔드 | 비디오 업로드 API | ✅ 완료 |
| 백엔드 | 비디오 CRUD API | ✅ 완료 |
| 백엔드 | **이미지 업로드 API** | ✅ 완료 |
| 백엔드 | **이미지 CRUD API** | ✅ 완료 |
| 백엔드 | Ollama 클라이언트 유틸리티 | ✅ 완료 |
| 백엔드 | FFmpeg 유틸리티 | ✅ 완료 |
| 백엔드 | 비디오 태깅 서비스 | ✅ 완료 |
| 백엔드 | **이미지 태깅 서비스** | ✅ 완료 |
| 백엔드 | 검색 API (AND/OR/NOT) | ✅ 완료 |
| 백엔드 | 장면 내보내기 API | ✅ 완료 |
| 프론트엔드 | Next.js 기본 구조 | ✅ 완료 |
| 프론트엔드 | 업로드 페이지 (동영상 + 사진) | ✅ 완료 |
| 프론트엔드 | 비디오 목록/상세 페이지 | ✅ 완료 |
| 프론트엔드 | **이미지 목록/상세 페이지** | ✅ 완료 |
| 프론트엔드 | 검색 페이지 (동영상 + 사진 + 장면) | ✅ 완료 |
| 프론트엔드 | 비디오 플레이어 + 장면 타임라인 | ✅ 완료 |

### 2.2 테스트 완료 항목

| 테스트 항목 | 결과 | 테스트 일시 |
|-------------|------|-------------|
| 비디오 업로드 API | ✅ 성공 | 2026-01-26 17:12 |
| 이미지 업로드 API | ✅ 성공 | 2026-01-27 |
| 파일 저장 확인 | ✅ 성공 | 2026-01-26 17:12 |
| DB 저장 확인 | ✅ 성공 | 2026-01-26 17:12 |
| 비디오 목록 조회 | ✅ 성공 | 2026-01-26 17:14 |
| 이미지 목록 조회 | ✅ 성공 | 2026-01-27 |
| 비디오 태깅 완료 | ✅ 성공 | 2026-01-26 17:45 |
| 이미지 태깅 완료 | ✅ 성공 | 2026-01-27 |
| 검색 기능 (AND/OR/NOT) | ✅ 성공 | 2026-01-26 17:50 |

---

## 3. 구현 단계 개요

```
Phase 1: 비디오 메타데이터 자동 생성 ✅
    ├── Step 1.1: 비디오 정보 자동 추출 (duration, file_size) ✅
    ├── Step 1.2: Ollama 연동 - 비디오 요약 생성 ✅
    └── Step 1.3: Ollama 연동 - 비디오 태그 생성 ✅

Phase 2: 장면 분할 및 태깅 ✅
    ├── Step 2.1: PySceneDetect 장면 감지 ✅
    ├── Step 2.2: 장면별 썸네일/클립 생성 ✅
    └── Step 2.3: 장면별 태그 생성 ✅

Phase 3: 이미지 메타데이터 및 태깅 ✅ (신규)
    ├── Step 3.1: 이미지 업로드 및 썸네일 생성 ✅
    ├── Step 3.2: Ollama 연동 - 이미지 설명 생성 ✅
    └── Step 3.3: Ollama 연동 - 이미지 태그 생성 ✅

Phase 4: 검색 기능 ✅
    ├── Step 4.1: 태그 목록 API ✅
    ├── Step 4.2: AND/OR/NOT 검색 로직 ✅
    ├── Step 4.3: 이미지 검색 추가 ✅ (신규)
    └── Step 4.4: 프론트엔드 검색 연동 ✅

Phase 5: 장면 내보내기 ✅
    ├── Step 5.1: 장면 상세 조회 API ✅
    ├── Step 5.2: 장면 다운로드 API ✅
    └── Step 5.3: 장면 병합 내보내기 ✅

Phase 6: 비디오 플레이어 ✅
    ├── Step 6.1: React Player 통합 ✅
    ├── Step 6.2: 장면 타임라인 표시 ✅
    └── Step 6.3: 장면 클릭 시 해당 위치 이동 ✅

Phase 7: UI/UX 개선 ✅
    ├── Step 7.1: 실시간 처리 상태 표시 ✅
    ├── Step 7.2: 에러 처리 개선 ✅
    └── Step 7.3: 반응형 디자인 점검 ✅

Phase 8: 외부 API 연동 (미구현)
    ├── Step 8.1: Google Nanobana API 연동
    └── Step 8.2: 동영상 제작 요청 기능
```

---

## 4. Phase 1: 비디오 메타데이터 자동 생성 ✅

### 4.1 목표
- 업로드된 비디오의 메타데이터를 자동으로 추출하고 AI 기반 요약/태그 생성

### 4.2 테스트 결과 요약

| Step | 결과 | 비고 |
|------|------|------|
| 1.1 비디오 정보 추출 | ✅ 성공 | FFmpeg로 duration 추출 |
| 1.2 비디오 요약 생성 | ✅ 성공 | 3개 프레임 추출 후 Ollama 비전 분석 |
| 1.3 비디오 태그 생성 | ✅ 성공 | 3-10개 한국어 태그 생성 |

---

## 5. Phase 2: 장면 분할 및 태깅 ✅

### 5.1 목표
- 비디오를 장면 단위로 분할하고 각 장면에 태그 생성

### 5.2 테스트 결과 요약

| Step | 결과 | 비고 |
|------|------|------|
| 2.1 장면 감지 | ✅ 성공 | PySceneDetect ContentDetector 사용 |
| 2.2 썸네일/클립 생성 | ✅ 성공 | 장면 중간 지점 썸네일, 온디맨드 클립 생성 |
| 2.3 장면별 태그 생성 | ✅ 성공 | 장면당 3-7개 태그, 장면 태그 집계 |

---

## 6. Phase 3: 이미지 메타데이터 및 태깅 ✅ (신규)

### 6.1 목표
- 업로드된 이미지의 메타데이터를 자동으로 추출하고 AI 기반 설명/태그 생성

### 6.2 관련 요구사항
- FR-001-1: 사진 업로드
- FR-002-1: 사진 자동 메타데이터 생성
- FR-006-1, FR-006-2, FR-006-3: 사진 AI 분석 및 태그 생성

---

### Step 3.1: 이미지 업로드 및 썸네일 생성

#### 구현 내용
| 파일 | 수정 내용 |
|------|-----------|
| `backend/app/models/image.py` | Image 모델 정의 |
| `backend/app/api/routes/images.py` | 이미지 업로드 API |

#### 구현 상세
```python
# image.py
class Image(Base):
    __tablename__ = "images"

    id = Column(UUID, primary_key=True, default=uuid.uuid4)
    filename = Column(String(255), nullable=False)
    title = Column(String(500))
    description = Column(Text)  # AI 생성 설명
    user_notes = Column(Text)
    file_path = Column(String(1000), nullable=False)
    thumbnail_path = Column(String(1000))
    width = Column(Integer)
    height = Column(Integer)
    file_size = Column(BigInteger)
    status = Column(String(50), default="uploaded")
    created_at = Column(DateTime, default=datetime.utcnow)
    updated_at = Column(DateTime, default=datetime.utcnow)

    tags = relationship("Tag", secondary="image_tags", back_populates="images")
```

#### 테스트 결과
| 테스트 케이스 | 결과 | 일시 | 비고 |
|---------------|------|------|------|
| 이미지 업로드 | ✅ 성공 | 2026-01-27 | JPG, PNG 지원 |
| 썸네일 생성 | ✅ 성공 | 2026-01-27 | Pillow로 썸네일 생성 |
| 메타데이터 추출 | ✅ 성공 | 2026-01-27 | width, height, file_size |

---

### Step 3.2: Ollama 연동 - 이미지 설명 생성

#### 구현 내용
| 파일 | 수정 내용 |
|------|-----------|
| `backend/app/services/image_tagging_service.py` | 신규 생성 |

#### 구현 상세
```python
# image_tagging_service.py
class ImageTaggingService:
    async def generate_description(self, image_id: UUID, db: Session):
        image = db.query(Image).filter(Image.id == image_id).first()

        # 이미지 파일 읽기
        with open(image.file_path, "rb") as f:
            image_data = base64.b64encode(f.read()).decode()

        # Ollama 비전 모델로 설명 생성
        prompt = "이 이미지를 한국어로 2-3문장으로 설명해주세요."
        description = await self.ollama.generate_with_images(prompt, [image_data])

        image.description = description
        db.commit()
```

#### 테스트 결과
| 테스트 케이스 | 결과 | 일시 | 비고 |
|---------------|------|------|------|
| 설명 생성 | ✅ 성공 | 2026-01-27 | 한국어 2-3문장 설명 |
| Ollama 비전 연동 | ✅ 성공 | 2026-01-27 | gemma3:27b 모델 사용 |

---

### Step 3.3: Ollama 연동 - 이미지 태그 생성

#### 구현 내용
| 파일 | 수정 내용 |
|------|-----------|
| `backend/app/services/image_tagging_service.py` | generate_image_tags() 메서드 |
| `backend/app/models/tag.py` | ImageTag 모델 추가 |

#### 구현 상세
```python
async def generate_image_tags(self, image_id: UUID, db: Session):
    image = db.query(Image).filter(Image.id == image_id).first()

    # 이미지 분석하여 5-15개 태그 생성
    prompt = """이 이미지를 분석하여 5-15개의 한국어 태그를 생성해주세요.
    태그는 쉼표로 구분하여 출력해주세요."""

    with open(image.file_path, "rb") as f:
        image_data = base64.b64encode(f.read()).decode()

    response = await self.ollama.generate_with_images(prompt, [image_data])
    tags = [t.strip() for t in response.split(",")]

    for tag_name in tags[:15]:
        tag = db.query(Tag).filter(Tag.name == tag_name).first()
        if not tag:
            tag = Tag(name=tag_name)
            db.add(tag)
            db.flush()

        image_tag = ImageTag(image_id=image.id, tag_id=tag.id)
        db.add(image_tag)

    image.status = "tagged"
    db.commit()
```

#### 테스트 결과
| 테스트 케이스 | 결과 | 일시 | 비고 |
|---------------|------|------|------|
| 태그 생성 | ✅ 성공 | 2026-01-27 | 5-15개 태그 생성 |
| image_tags 저장 | ✅ 성공 | 2026-01-27 | ImageTag 레코드 생성 |

---

## 7. Phase 4: 검색 기능 ✅

### 7.1 목표
- 태그 기반 AND/OR/NOT 검색 구현 (동영상, 사진, 장면 모두 검색)

### 7.2 테스트 결과 요약

| Step | 결과 | 비고 |
|------|------|------|
| 4.1 태그 목록 API | ✅ 성공 | video_count, scene_count, image_count 포함 |
| 4.2 AND/OR/NOT 검색 | ✅ 성공 | 복합 검색 지원 |
| 4.3 이미지 검색 | ✅ 성공 | images 테이블 검색 추가 |
| 4.4 프론트엔드 연동 | ✅ 성공 | 검색 결과에 이미지 표시 |

---

### Step 4.3: 이미지 검색 추가 (신규)

#### 구현 내용
| 파일 | 수정 내용 |
|------|-----------|
| `backend/app/api/routes/search.py` | 이미지 검색 로직 추가 |

#### 구현 상세
```python
# search.py
@router.post("/")
async def search(query: SearchQuery, db: Session = Depends(get_db)):
    results = {
        "videos": [],
        "scenes": [],
        "images": []  # 이미지 검색 결과 추가
    }

    # AND/OR/NOT 로직으로 이미지 검색
    if "images" in query.target:
        image_ids = search_images(query, db)
        results["images"] = [
            {
                "id": img.id,
                "title": img.title or img.filename,
                "description": img.description,
                "thumbnail_path": img.thumbnail_path,
                "tags": [t.name for t in img.tags]
            }
            for img in db.query(Image).filter(Image.id.in_(image_ids)).all()
        ]

    return results
```

#### 테스트 결과
| 테스트 케이스 | 결과 | 일시 | 비고 |
|---------------|------|------|------|
| 이미지 AND 검색 | ✅ 성공 | 2026-01-27 | 여러 태그 모두 포함 |
| 이미지 OR 검색 | ✅ 성공 | 2026-01-27 | 태그 중 하나 포함 |
| 이미지 NOT 검색 | ✅ 성공 | 2026-01-27 | 특정 태그 제외 |

---

## 8. Phase 5: 장면 내보내기 ✅

### 8.1 테스트 결과 요약

| Step | 결과 | 비고 |
|------|------|------|
| 5.1 장면 상세 조회 | ✅ 성공 | 장면 정보 + 태그 반환 |
| 5.2 장면 다운로드 | ✅ 성공 | 온디맨드 클립 생성 및 다운로드 |
| 5.3 장면 병합 | ✅ 성공 | FFmpeg concat으로 병합 |

---

## 9. Phase 6: 비디오 플레이어 ✅

### 9.1 테스트 결과 요약

| Step | 결과 | 비고 |
|------|------|------|
| 6.1 React Player | ✅ 성공 | Range 요청 지원, 커스텀 컨트롤 |
| 6.2 장면 타임라인 | ✅ 성공 | 색상 구분, 현재 위치 표시 |
| 6.3 장면 클릭 이동 | ✅ 성공 | seekTo() 사용 |

---

## 10. Phase 7: UI/UX 개선 ✅

### 10.1 테스트 결과 요약

| Step | 결과 | 비고 |
|------|------|------|
| 7.1 처리 상태 표시 | ✅ 성공 | useTaggingStatus 훅, 2초 폴링 |
| 7.2 에러 처리 | ✅ 성공 | ErrorBoundary, Toast 알림 |
| 7.3 반응형 디자인 | ✅ 성공 | Desktop/Tablet/Mobile 지원 |

---

## 11. 디렉토리 구조 (최종)

```
mediaTagging/
├── backend/
│   ├── app/
│   │   ├── api/
│   │   │   └── routes/
│   │   │       ├── videos.py      # 비디오 API
│   │   │       ├── images.py      # 이미지 API ✅ (신규)
│   │   │       ├── scenes.py      # 장면 API
│   │   │       ├── search.py      # 검색 API (이미지 검색 포함)
│   │   │       └── external.py    # 외부 API
│   │   ├── models/
│   │   │   ├── database.py
│   │   │   ├── video.py
│   │   │   ├── image.py           # ✅ (신규)
│   │   │   ├── scene.py
│   │   │   └── tag.py             # ImageTag 추가
│   │   ├── schemas/
│   │   │   ├── video.py
│   │   │   ├── image.py           # ✅ (신규)
│   │   │   ├── scene.py
│   │   │   └── search.py
│   │   ├── services/
│   │   │   ├── tagging_service.py
│   │   │   └── image_tagging_service.py  # ✅ (신규)
│   │   ├── utils/
│   │   │   ├── video_processor.py
│   │   │   ├── scene_detector.py
│   │   │   └── ollama_client.py
│   │   ├── config.py
│   │   └── main.py
│   └── alembic/
├── frontend/
│   └── src/
│       ├── app/
│       │   ├── page.tsx           # 홈 (4개 카드: 업로드, 동영상, 사진, 검색)
│       │   ├── layout.tsx
│       │   ├── providers.tsx
│       │   ├── upload/page.tsx    # 동영상 + 사진 업로드
│       │   ├── videos/
│       │   │   ├── page.tsx
│       │   │   └── [id]/page.tsx
│       │   ├── images/            # ✅ (신규)
│       │   │   ├── page.tsx       # 이미지 목록
│       │   │   └── [id]/page.tsx  # 이미지 상세
│       │   └── search/page.tsx    # 동영상 + 이미지 + 장면 검색
│       ├── components/
│       │   ├── Navbar.tsx
│       │   ├── VideoPlayer.tsx
│       │   ├── SceneTimeline.tsx
│       │   ├── ProcessingStatus.tsx
│       │   ├── Toast.tsx
│       │   └── ErrorBoundary.tsx
│       ├── hooks/
│       │   └── useTaggingStatus.ts
│       ├── lib/
│       │   ├── api.ts             # 이미지 API 함수 추가
│       │   └── utils.ts
│       └── types/
│           └── index.ts           # Image 타입 추가
├── storage/
│   ├── videos/
│   ├── images/                    # ✅ (신규)
│   ├── clips/
│   ├── thumbnails/
│   │   └── images/                # ✅ (신규)
│   └── exports/
├── docker-compose.yml
└── zWorkingDocs/
    ├── 요구사항분석_v20260127.md
    ├── 시스템설계_v20260127.md
    └── 구현설계_v20260127.md
```

---

## 12. 프론트엔드 페이지 구성

### 12.1 홈 페이지 (/)
- 4개의 카드 형태 메뉴
  - 파일 업로드 (동영상/사진)
  - 동영상 관리
  - 사진 관리
  - 검색

### 12.2 업로드 페이지 (/upload)
- 드래그 앤 드롭 지원
- 동영상: MP4, MOV, AVI, MKV, WebM, WMV, FLV
- 사진: JPG, JPEG, PNG, GIF, WebP, BMP, TIFF
- 업로드 진행률 표시

### 12.3 동영상 목록 (/videos)
- 동영상 카드 그리드
- 상태 배지 (업로드됨/처리 중/태깅 완료/오류)
- 요약, 재생 시간, 파일 크기 표시

### 12.4 동영상 상세 (/videos/[id])
- 좌측 (2/3): 비디오 플레이어, 장면 타임라인, AI 요약
- 우측 (1/3): 상태, 태깅 버튼, 태그 목록, 장면 목록

### 12.5 사진 목록 (/images)
- 사진 카드 그리드 (반응형 2/3/4열)
- 상태 배지
- 설명, 치수, 파일 크기, 태그 수 표시

### 12.6 사진 상세 (/images/[id])
- 원본 이미지 표시
- AI 설명
- 태그 목록 (AI 태그/사용자 태그 구분)
- 태깅 시작 버튼
- 다운로드 버튼

### 12.7 검색 페이지 (/search)
- 검색 모드: AND (파란색), OR (초록색), NOT (빨간색)
- 태그 입력 또는 버튼 클릭
- 검색 결과: 동영상, 사진, 장면 탭 구분

---

## 13. 태그 처리 로직

### 13.1 AI 태그
- 동영상: 요약 기반 3-10개, 장면 기반 집계
- 사진: 이미지 분석 5-15개
- 장면: 3개 프레임 분석 3-7개
- UI 표시: 파란색 배지

### 13.2 사용자 정의 태그
- user_notes 필드에 #태그 형식으로 입력
- 정규식 파싱: `r'#([\w가-힣]+)'`
- confidence = 1.0으로 마킹
- UI 표시: 보라색 배지

---

## 14. 변경 이력

| 버전 | 날짜 | 작성자 | 변경 내용 |
|------|------|--------|----------|
| v20260126172234 | 2026-01-26 | - | 최초 작성 |
| v20260127 | 2026-01-27 | - | 이미지 태깅 기능 추가 (Phase 3), 이미지 검색 추가 (Step 4.3), 디렉토리 구조 업데이트, 프론트엔드 페이지 구성 추가 |
